import akshare as ak
import pandas as pd
from datetime import datetime, timedelta
import time
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
import warnings
from typing import Callable, Dict, Any, List
import pandas_ta as ta
import numpy as np
import xlsxwriter

# 忽略 pandas 的 SettingWithCopyWarning
warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)


# ==============================================================================
# 工具函数
# ==============================================================================
def format_stock_code(code: str) -> str:
    """根据股票代码的开头数字，添加SH或SZ前缀。"""
    code_str = str(code).zfill(6)
    if code_str.startswith('6'):
        return 'sh' + code_str
    elif code_str.startswith(('0', '3')):
        return 'sz' + code_str
    elif code_str.startswith(('4', '8')):
        return 'bj' + code_str
    return code_str


# ==============================================================================
# 配置类
# ==============================================================================
class Config:
    """
    程序配置类，用于管理路径、重试次数等全局设置。
    """

    def __init__(self):
        self.HOME_DIRECTORY = os.path.expanduser('~')
        self.SAVE_DIRECTORY = os.path.join(self.HOME_DIRECTORY, 'Downloads', 'CoreNews_Reports')
        self.TEMP_DATA_DIRECTORY = os.path.join(self.SAVE_DIRECTORY, 'ShareData')
        self.DATA_FETCH_RETRIES = 5
        self.DATA_FETCH_DELAY = 10
        self.MAX_WORKERS = 16


# ==============================================================================
# 数据获取类
# ==============================================================================
class DataFetcher:
    """
    负责从 Akshare 获取数据，并实现缓存和并行下载功能。
    """

    def __init__(self, config: Config):
        self.config = config
        self.today_str = datetime.now().strftime("%Y%m%d")
        self.executor = ThreadPoolExecutor(max_workers=self.config.MAX_WORKERS)
        os.makedirs(self.config.TEMP_DATA_DIRECTORY, exist_ok=True)
        self.macd_cache_file = os.path.join(self.config.TEMP_DATA_DIRECTORY, 'MACD_hist_data_cache.txt')

    def get_file_path(self, base_name: str, is_cleaned: bool = False) -> str:
        """根据基础文件名和当前日期生成完整的文件路径。如果 is_cleaned 为 True，则添加 '_经清洗' 后缀。"""
        suffix = "_经清洗" if is_cleaned else ""
        file_name = f"{base_name}{suffix}_{self.today_str}.txt"
        return os.path.join(self.config.TEMP_DATA_DIRECTORY, file_name)

    def load_data_from_txt(self, file_path: str) -> pd.DataFrame:
        """从 | 分隔的 TXT 文件加载数据。"""
        if os.path.exists(file_path):
            try:
                # 尝试加载数据
                df = pd.read_csv(file_path, sep='|', encoding='utf-8', dtype={'股票代码': str})
                return df
            except Exception as e:
                print(f"[WARN] 错误：加载临时文件 {os.path.basename(file_path)} 失败: {e}，将重新获取。")
        return pd.DataFrame()

    def save_data_to_txt(self, df: pd.DataFrame, file_path: str):
        """将 DataFrame 保存到 | 分隔的 TXT 文件。"""
        try:
            df.to_csv(file_path, sep='|', index=False, encoding='utf-8')
            print(f"数据已保存到临时文件: {os.path.basename(file_path)}")
        except Exception as e:
            print(f"[ERROR] 错误：保存数据到临时文件 {os.path.basename(file_path)} 失败: {e}")

    def fetch_with_cache(self, fetch_func: Callable, file_base_name: str, **kwargs: Any) -> pd.DataFrame:
        """带缓存和重试功能的数据获取函数，优先检查已清洗缓存。"""

        # 1. 优先检查是否存在已清洗的缓存文件
        cleaned_file_path = self.get_file_path(file_base_name, is_cleaned=True)
        cached_cleaned_df = self.load_data_from_txt(cleaned_file_path)
        if not cached_cleaned_df.empty:
            print(f"发现已清洗缓存文件: {os.path.basename(cleaned_file_path)}，直接加载数据。")
            return cached_cleaned_df

        # 2. 检查是否存在未清洗的缓存文件
        raw_file_path = self.get_file_path(file_base_name, is_cleaned=False)
        cached_raw_df = self.load_data_from_txt(raw_file_path)
        if not cached_raw_df.empty:
            print(f"发现原始临时文件: {os.path.basename(raw_file_path)}，直接加载数据。")
            return cached_raw_df  # 返回未清洗的，让 processor 重新清洗并保存/删除

        # 3. 如果都没有，则进行 API 抓取
        for i in range(self.config.DATA_FETCH_RETRIES):
            try:
                print(f"正在尝试第 {i + 1}/{self.config.DATA_FETCH_RETRIES} 次获取数据: {file_base_name}...")
                df = fetch_func(**kwargs)
                if df is not None and not df.empty:
                    print("数据获取成功。")
                    self.save_data_to_txt(df, raw_file_path)  # 保存原始数据
                    return df
                else:
                    print("[WARN] 数据返回为空或无效，将重试。")
                    time.sleep(self.config.DATA_FETCH_DELAY)
            except Exception as e:
                print(f"[ERROR] 获取数据时出错: {e}，将在 {self.config.DATA_FETCH_DELAY} 秒后重试。")
                time.sleep(self.config.DATA_FETCH_DELAY)
        print(f"[ERROR] 所有重试均失败，将返回空 DataFrame: {file_base_name}")
        return pd.DataFrame()

    def get_top_industry_stocks(self) -> pd.DataFrame:
        """
        获取涨跌幅前五的板块及其成分股，并进行规范化处理。
        """
        print("\n>>> 正在获取东方财富-沪深京板块-行业板块数据...")
        # 1. 获取行业板块名称列表
        # 注意：这里获取的行业板块名称列表不涉及清洗（ST过滤等），因此不应该调用 clean_data
        all_industries_df = self.fetch_with_cache(ak.stock_board_industry_name_em, '行业板块名称')
        if all_industries_df.empty:
            print("警告：未能获取行业板块名称列表，无法获取成分股。")
            return pd.DataFrame()
        top_industries = all_industries_df.sort_values(by='涨跌幅', ascending=False).head(10)
        if top_industries.empty:
            print("警告：未能找到涨幅前的板块。")
            return pd.DataFrame()
        print(f"  - 涨跌幅前排板块是: {top_industries['板块名称'].tolist()}")
        all_constituents = []
        with ThreadPoolExecutor(max_workers=self.config.MAX_WORKERS) as executor:
            future_to_industry = {
                executor.submit(
                    self.fetch_with_cache,
                    ak.stock_board_industry_cons_em,
                    f"板块成分股_{row['板块名称']}",
                    symbol=row['板块名称']
                ): row['板块名称']
                for _, row in top_industries.iterrows()
            }
            for future in as_completed(future_to_industry):
                industry_name = future_to_industry[future]
                try:
                    constituents_df = future.result()
                    if not constituents_df.empty:
                        print(f"  - 成功获取板块 '{industry_name}' 的成分股。")
                        # 添加板块名称列
                        constituents_df['所属板块'] = industry_name
                        # 确保股票代码列为字符串格式，防止0丢失
                        if '代码' in constituents_df.columns:
                            constituents_df.rename(columns={'代码': '股票代码'}, inplace=True)
                        constituents_df['股票代码'] = constituents_df['股票代码'].astype(str).str.zfill(6)
                        constituents_df['完整股票编码'] = constituents_df['股票代码'].apply(format_stock_code)
                        all_constituents.append(constituents_df)
                    else:
                        print(f"  - 警告：未能获取板块 '{industry_name}' 的成分股数据。")
                except Exception as e:
                    print(f"  - [ERROR] 获取板块 '{industry_name}' 成分股时出错: {e}")

        if all_constituents:
            merged_df = pd.concat(all_constituents, ignore_index=True)
            print(f"  - 已合并所有前板块成分股数据，共 {len(merged_df)} 条。")
            return merged_df
        else:
            print("  - 所有板块成分股数据均获取失败。")
            return pd.DataFrame()

    # >> 新增持续放量数据的获取方法
    def fetch_continuous_volume_increase(self) -> pd.DataFrame:
        """
        获取同花顺-持续放量数据。
        接口: ak.stock_rank_cxfl_ths
        """
        print("\n>>> 正在获取同花顺-持续放量数据...")
        # Note: The file base name should match the name used in processor
        df = self.fetch_with_cache(ak.stock_rank_cxfl_ths, '持续放量')
        return df

    # << 新增持续放量数据的获取方法

    def fetch_hist_data_parallel(self, codes: list, days: int) -> pd.DataFrame:
        """并行获取指定股票代码的历史数据，并缓存到本地文件。"""
        print(f"\n正在为 {len(codes)} 只股票下载 {days} 天的历史数据，使用15个线程并行处理。")
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)
        start_date_str = start_date.strftime("%Y%m%d")
        end_date_str = end_date.strftime("%Y%m%d")
        if os.path.exists(self.macd_cache_file):
            # 检查缓存是否过期（例如，如果缓存不是今天创建的，则重新下载）
            cache_date = datetime.fromtimestamp(os.path.getmtime(self.macd_cache_file)).strftime("%Y%m%d")
            if cache_date == self.today_str:
                print(f"发现今日历史数据缓存文件，直接加载。")
                return pd.read_csv(self.macd_cache_file, sep='|', encoding='utf-8', dtype={'股票代码': str})
            else:
                print("发现旧的历史数据缓存文件，将重新下载。")

        all_data = []
        # 将代码转换为完整的市场编码
        future_to_code = {}
        with ThreadPoolExecutor(max_workers=15) as executor:
            for code in codes:
                future = executor.submit(
                    ak.stock_zh_a_hist_tx,
                    symbol=format_stock_code(code),
                    start_date=start_date_str,
                    end_date=end_date_str,
                    adjust="hfq"
                )
                future_to_code[future] = code

            for i, future in enumerate(as_completed(future_to_code)):
                code = future_to_code[future]
                try:
                    hist_df = future.result()
                    if hist_df is not None and not hist_df.empty:
                        hist_df['股票代码'] = code
                        # 确保日期是字符串格式，避免excel出错
                        if '日期' in hist_df.columns:
                            hist_df['日期'] = pd.to_datetime(hist_df['日期']).dt.strftime('%Y-%m-%d')
                        all_data.append(hist_df)

                except Exception as e:
                    print(f"[ERROR] 错误：获取 {code} 的历史数据时出错: {e}，已跳过。")
        if all_data:
            merged_df = pd.concat(all_data, ignore_index=True)
            self.save_data_to_txt(merged_df, self.macd_cache_file)
            return merged_df
        print("[WARN] 未能成功下载任何股票的历史数据。")
        return pd.DataFrame()

    # >> NEW: 添加获取单个股票所属行业信息的方法
    def fetch_industry_info(self, code: str) -> Dict[str, str]:
        """为单个股票代码获取所属行业信息 (ak.stock_individual_info_em)。"""
        try:
            # 使用 ak.stock_individual_info_em 获取股票信息
            info_df = ak.stock_individual_info_em(symbol=code)

            # 查找 '行业' 字段的值
            industry = info_df[info_df['项目'] == '所属行业']['值'].iloc[0]
            return {code: industry}
        except Exception:
            # print(f"[WARN] 获取 {code} 行业信息失败: {e}")
            return {code: 'N/A'}

    def get_industry_map_parallel(self, codes: List[str]) -> Dict[str, str]:
        """并行获取多个股票代码的所属行业信息，使用 5 个工作线程。"""
        # --- 核心修改：将 max_workers 显式设置为 5 ---
        MAX_INDUSTRY_WORKERS = 5
        print(f"\n正在并行获取 {len(codes)} 只股票的所属行业信息，使用 {MAX_INDUSTRY_WORKERS} 个线程...")
        
        industry_map = {}
        future_to_code = {}

        # 重新创建 executor 以确保线程池独立且只使用 5 个 workers
        with ThreadPoolExecutor(max_workers=MAX_INDUSTRY_WORKERS) as executor:
            for code in codes:
                future = executor.submit(self.fetch_industry_info, code)
                future_to_code[future] = code

            for i, future in enumerate(as_completed(future_to_code)):
                code = future_to_code[future]
                try:
                    result = future.result()
                    industry_map.update(result)

                    if (i + 1) % 50 == 0 or (i + 1) == len(codes):
                        print(f"  - 进度: 已处理 {i + 1}/{len(codes)} 只股票的行业信息。")
                except Exception:
                    # 失败时已在 fetch_industry_info 中处理，这里只记录
                    industry_map[code] = 'N/A'

        print("所属行业信息获取完成。")
        return industry_map
    # << NEW: 添加获取单个股票所属行业信息的方法


# ==============================================================================
# 数据处理类
# ==============================================================================
class DataProcessor:
    """
    负责对获取的数据进行清洗、合并和技术指标计算。
    """

    def __init__(self, data_fetcher: DataFetcher):
        self.fetcher = data_fetcher
        self.executor = ThreadPoolExecutor(max_workers=self.fetcher.config.MAX_WORKERS)
        self.start_date_for_ta = (datetime.now() - pd.DateOffset(months=6)).strftime("%Y%m%d")
        self.end_date_for_ta = datetime.now().strftime("%Y%m%d")
        self.code_aliases = {'代码': '股票代码', '股票代码': '股票代码', '证券代码': '股票代码'}
        self.name_aliases = {'名称': '股票简称', '股票名称': '股票简称', '股票简称': '股票简称'}
        self.price_aliases = {'最新价': '最新价', '现价': '最新价'}

    def standardize_columns(self, df: pd.DataFrame) -> pd.DataFrame:
        """标准化 DataFrame 的列名，确保'股票代码'和'股票简称'等列存在。"""
        if df.empty:
            return df
        found_code_col = False
        for old_name, new_name in self.code_aliases.items():
            if old_name in df.columns:
                df.rename(columns={old_name: new_name}, inplace=True)
                found_code_col = True
                break
        if not found_code_col:
            # print(f"[WARN] 未能在数据中找到股票代码列，原始列名: {df.columns.tolist()}")
            return pd.DataFrame()
        found_name_col = False
        for old_name, new_name in self.name_aliases.items():
            if old_name in df.columns:
                df.rename(columns={old_name: new_name}, inplace=True)
                found_name_col = True
                break
        if not found_name_col and '股票简称' not in df.columns:
            # print(f"[WARN] 未能在数据中找到股票名称列，原始列名: {df.columns.tolist()}")
            pass  # 允许没有股票简称，但可能有股票代码
        found_price_col = False
        for old_name, new_name in self.price_aliases.items():
            if old_name in df.columns:
                df.rename(columns={old_name: new_name}, inplace=True)
                found_price_col = True
                break
        if not found_price_col and '最新价' not in df.columns:
            # print(f"[WARN] 未能在数据中找到价格列，原始列名: {df.columns.tolist()}")
            pass
        return df

    def clean_data(self, df: pd.DataFrame, df_name: str) -> pd.DataFrame:
        """通用数据清洗函数，处理缺失值、重复值并去除ST股，并保存清洗后的数据，删除原始文件。"""
        initial_rows = len(df)

        # 1. 构造原始文件路径，用于删除
        today_str = self.fetcher.today_str
        original_file_name = f"{df_name}_{today_str}.txt"
        original_file_path = os.path.join(self.fetcher.config.TEMP_DATA_DIRECTORY, original_file_name)

        # 2. 执行清洗和标准化
        df = self.standardize_columns(df)
        if df.empty or '股票代码' not in df.columns:
            print(f"[WARN] {df_name} 数据标准化失败或为空，跳过清洗。")
            return pd.DataFrame()

        df.dropna(subset=['股票代码'], inplace=True)
        df.drop_duplicates(subset=['股票代码'], inplace=True)
        df['股票代码'] = df['股票代码'].astype(str).str.zfill(6)

        # 优化：在清洗前添加一个临时的股票简称列，以防缺失，方便ST过滤
        if '股票简称' not in df.columns:
            df['股票简称'] = df['股票代码'].astype(str)  # 临时使用代码

        cleaned_df = df[~df['股票简称'].str.contains('ST|st|退市', case=False, na=False)].copy()

        # 恢复原始的股票简称列（如果临时添加了）
        if '股票简称' in df.columns and cleaned_df.columns.tolist()[
            -1] == '股票简称' and '股票简称' not in self.name_aliases.values():
            pass

        final_rows = len(cleaned_df)
        print(f"{df_name} 清洗完成。清洗前：{initial_rows} 条，清洗后：{final_rows} 条。")

        # 3. 构造并保存清洗后的文件
        cleaned_file_name = f"{df_name}_经清洗_{today_str}.txt"
        cleaned_file_path = os.path.join(self.fetcher.config.TEMP_DATA_DIRECTORY, cleaned_file_name)
        self.fetcher.save_data_to_txt(cleaned_df, cleaned_file_path)

        # 4. 删除原始文件
        try:
            # 只有当原始文件存在（即未命中清洗缓存）时才删除
            if os.path.exists(original_file_path):
                os.remove(original_file_path)
                print(f"已删除原始临时文件: {original_file_name}")
        except Exception as e:
            print(f"[WARN] 警告：删除原始文件 {original_file_name} 失败: {e}")

        return cleaned_df

    def process_profit_data(self, df: pd.DataFrame, min_rating: int = 2) -> pd.DataFrame:
        df = self.clean_data(df, "主力研报盈利预测")
        if df.empty:
            return pd.DataFrame()
        df['机构投资评级(近六个月)-买入'] = pd.to_numeric(df['机构投资评级(近六个月)-买入'], errors='coerce')
        df = df[df['机构投资评级(近六个月)-买入'] >= min_rating].copy()
        df['完整股票编码'] = df['股票代码'].apply(format_stock_code)
        print(f"研报数据过滤完成，符合条件的股票数量: {len(df)}")
        return df

    def process_main_report_sheet(self, profit_df: pd.DataFrame, spot_df: pd.DataFrame) -> pd.DataFrame:
        """生成“主力研报筛选” Sheet 的数据，不再包含股票链接、最新价、序号。"""
        if profit_df.empty:
            print("[WARN] 研报数据为空，无法生成主力研报筛选表。")
            return pd.DataFrame()

        # 1. 使用 profit_df 的拷贝作为基础，不再合并 spot_df 中的 '最新价'
        final_df = profit_df.copy()

        # 2. 移除不再需要的列：'完整股票编码'（曾用于生成股票链接）
        cols_to_drop = ['完整股票编码']

        for col in cols_to_drop:
            if col in final_df.columns:
                final_df.drop(columns=[col], inplace=True)

        # 3. 确保 '股票代码' 和 '股票简称' 在最前面
        leading_cols = ['股票代码', '股票简称']
        existing_leading_cols = [col for col in leading_cols if col in final_df.columns]
        other_cols = [col for col in final_df.columns if col not in existing_leading_cols]

        # 返回最终筛选后的 DataFrame
        return final_df[existing_leading_cols + other_cols]

    def process_spot_data(self, spot_data_all: pd.DataFrame, filtered_codes_df: pd.DataFrame) -> pd.DataFrame:
        """处理实时行情数据，并确保价格列名为'当前价格'。"""
        # --- 核心修改：移除备用接口的获取和合并逻辑 ---
        # 仅处理传入的主接口数据
        spot_data_all = self.clean_data(spot_data_all, "A股实时行情")

        if spot_data_all.empty or filtered_codes_df.empty:
            # 如果是空DF，则只返回 spot_data_all 的清洗结果
            return spot_data_all

        # 核心修复：确保价格列名为'当前价格'，以便在 find_recommended_stocks_with_score 中区分使用
        if '最新价' in spot_data_all.columns:
            spot_data_all.rename(columns={'最新价': '当前价格'}, inplace=True)
        elif '现价' in spot_data_all.columns:
            spot_data_all.rename(columns={'现价': '当前价格'}, inplace=True)

        # 确保合并后保留'股票代码'和'当前价格'
        # 注意：这里不需要 filtered_codes_df，因为 spot_data_all 是 A股全量的实时行情，直接返回即可
        return spot_data_all[['股票代码', '股票简称', '当前价格']].drop_duplicates(subset=['股票代码'])
        # -----------------------------------------------

    def process_market_fund_flow(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        处理市场资金流向数据 (5日排行)。
        """
        # 注意：clean_data 会将价格列（如'最新价'）标准化为 '最新价'
        df = self.clean_data(df, "市场资金流向")
        if df.empty:
            print("警告：未能获取市场资金流向数据。")
            return pd.DataFrame()
        # 按照“流入资金”字段倒序排序
        if '流入资金' in df.columns:
            df['流入资金'] = pd.to_numeric(df['流入资金'], errors='coerce')
            df = df.sort_values(by='流入资金', ascending=False).copy()
        else:
            print("警告：未能找到 '流入资金' 列进行排序。")
        print(f"  - 资金流向数据处理成功，共 {len(df)} 条。")
        return df

    def process_general_rank(self, df: pd.DataFrame, name: str) -> pd.DataFrame:
        """通用排行榜数据处理，添加股票代码和编码。"""
        return self.clean_data(df, name)

    # >> 新增持续放量数据处理方法
    def process_continuous_volume_increase(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        处理持续放量数据，进行清洗和格式化。
        """
        df = self.clean_data(df, '持续放量')
        if df.empty:
            return pd.DataFrame()

        # 确保 '持续放量天数' 列存在且为数字
        if '持续放量天数' in df.columns:
            df['持续放量天数'] = pd.to_numeric(df['持续放量天数'], errors='coerce').fillna(0).astype(int)
        elif '放量天数' in df.columns:  # 兼容可能出现的字段名
            df.rename(columns={'放量天数': '持续放量天数'}, inplace=True)
            df['持续放量天数'] = pd.to_numeric(df['持续放量天数'], errors='coerce').fillna(0).astype(int)
        else:
            print("[WARN] '持续放量天数' 或 '放量天数' 列未找到，无法进行评分筛选。")
            df['持续放量天数'] = 0

        print(f"  - 持续放量数据处理成功，共 {len(df)} 条。")
        return df

    # << 新增持续放量数据处理方法

    def process_and_merge_xstp_data(self, df20: pd.DataFrame, df60: pd.DataFrame, df90: pd.DataFrame,
                                    spot_data_all: pd.DataFrame) -> pd.DataFrame:
        """处理并合并20日、60日和90日均线数据，并添加实时价格过滤。"""
        print("正在处理并合并20日、60日和90日均线数据...")

        # 使用 clean_data 并传入正确的 file_base_name
        processed_df20 = self.clean_data(df20, '向上突破20日均线').rename(columns={'最新价': '20日均线最新价'})
        processed_df60 = self.clean_data(df60, '向上突破60日均线').rename(columns={'最新价': '60日均线最新价'})
        processed_df90 = self.clean_data(df90, '向上突破90日均线').rename(columns={'最新价': '90日均线最新价'})

        if processed_df20.empty and processed_df60.empty and processed_df90.empty:
            print("[WARN] 所有均线数据均为空，无法合并。")
            return pd.DataFrame()

        # 初始合并
        merged_df = processed_df20[['股票代码', '股票简称', '20日均线最新价']].copy()

        # 合并 60日数据
        if not processed_df60.empty:
            merged_df = pd.merge(merged_df, processed_df60[['股票代码', '股票简称', '60日均线最新价']],
                                 on='股票代码', how='outer', suffixes=('_x', '_y'))
            merged_df['股票简称'] = merged_df['股票简称_x'].fillna(merged_df['股票简称_y'])
            merged_df.drop(columns=[c for c in ['股票简称_x', '股票简称_y'] if c in merged_df.columns], inplace=True)
            merged_df.drop_duplicates(subset=['股票代码'], inplace=True)

        # 合并 90日数据
        if not processed_df90.empty:
            merged_df = pd.merge(merged_df, processed_df90[['股票代码', '股票简称', '90日均线最新价']],
                                 on='股票代码', how='outer', suffixes=('_x', '_y'))
            merged_df['股票简称'] = merged_df['股票简称_x'].fillna(merged_df['股票简称_y'])
            merged_df.drop(columns=[c for c in ['股票简称_x', '股票简称_y'] if c in merged_df.columns], inplace=True)
            merged_df.drop_duplicates(subset=['股票代码'], inplace=True)

        final_cols = ['股票代码', '股票简称', '20日均线最新价', '60日均线最新价', '90日均线最新价']
        final_merged_df = merged_df[[col for col in final_cols if col in merged_df.columns]].copy()
        print("正在将实时价格合并到均线数据集中...")

        # 确保用于合并的spot_data_all DataFrame包含正确的列名
        spot_data_all_temp = spot_data_all.copy()
        if '最新价' in spot_data_all_temp.columns:
            spot_data_all_temp.rename(columns={'最新价': '当前价格'}, inplace=True)
        elif '现价' in spot_data_all_temp.columns:
            spot_data_all_temp.rename(columns={'现价': '当前价格'}, inplace=True)

        final_merged_df = pd.merge(final_merged_df, spot_data_all_temp[['股票代码', '当前价格']], on='股票代码',
                                   how='left')

        # 类型转换
        final_merged_df['20日均线最新价'] = pd.to_numeric(final_merged_df['20日均线最新价'], errors='coerce')
        final_merged_df['60日均线最新价'] = pd.to_numeric(final_merged_df['60日均线最新价'], errors='coerce')
        final_merged_df['90日均线最新价'] = pd.to_numeric(final_merged_df['90日均线最新价'], errors='coerce')
        final_merged_df['当前价格'] = pd.to_numeric(final_merged_df['当前价格'], errors='coerce')

        # 集中执行所有过滤条件:
        # 1. 名称不为空 2. 20日均线不为空 3. 当前价格不为空 4. 当前价格 > 20日均线
        filtered_df = final_merged_df[
            (final_merged_df['股票简称'].notna()) &
            (final_merged_df['20日均线最新价'].notna()) &
            (final_merged_df['当前价格'].notna()) &
            (final_merged_df['当前价格'] > final_merged_df['20日均线最新价'])
            ].copy()

        # 5. 添加多头排列条件 (20日>60日 或 60日>90日)
        # 按照原代码的逻辑实现：
        filtered_df = filtered_df[
            (filtered_df['20日均线最新价'] > filtered_df['60日均线最新价'].fillna(-np.inf)) |
            (filtered_df['60日均线最新价'] > filtered_df['90日均线最新价'].fillna(-np.inf))
            ].copy()

        # 6. 完全多头排列 (20日>60日>90日) - 可以在这里添加一个额外的列进行标记
        # 确保非空后再比较
        filtered_df['完全多头排列'] = filtered_df.apply(
            lambda row: '是' if row['20日均线最新价'] > row['60日均线最新价'] and row['60日均线最新价'] > row[
                '90日均线最新价'] else '否',
            axis=1
        )

        filtered_df.fillna('N/A', inplace=True)
        print(f"均线数据合并与过滤完成，符合条件的股票数量: {len(filtered_df)}")
        return filtered_df

    def process_all_technical_indicators(self, all_ta_codes: list, hist_df_all: pd.DataFrame,
                                         source_df: pd.DataFrame) -> Dict[str, pd.DataFrame]:
        """集中处理所有技术指标，避免重复计算。"""
        print(f"\n正在对 {len(all_ta_codes)} 只股票进行批量技术分析...")
        # 新增 'kdj' 结果列表
        results = {'macd': [], 'cci': [], 'rsi': [], 'boll': [], 'kdj': []}
        grouped = hist_df_all.groupby('股票代码')

        # 预先清理股票信息，用于查找简称
        source_df_clean = source_df[['股票代码', '股票简称']].drop_duplicates(subset=['股票代码'])

        for code, group_df in grouped:
            try:
                # 至少需要30条数据才能计算MACD/RSI/CCI/KDJ
                if len(group_df) < 30:
                    continue

                # 确保列名标准化
                group_df.rename(columns={'收盘': 'close', '最高': 'high', '最低': 'low'}, inplace=True)

                # --- MACD, CCI, RSI 计算 (使用 module syntax) ---
                macd_cols = ta.macd(group_df['close'], append=False)
                cci_cols = ta.cci(group_df['high'], group_df['low'], group_df['close'], append=False)
                rsi6_cols = ta.rsi(group_df['close'], length=6, append=False).rename('RSI_6')
                rsi14_cols = ta.rsi(group_df['close'], length=14, append=False).rename('RSI_14')

                # --- 新增 BOLL 计算 (默认长度20, 标准差2) ---
                boll_cols = ta.bbands(group_df['close'], append=False)

                # --- 新增 KDJ 计算 (默认周期 14, 3, 3) ---
                kdj_cols = ta.stoch(group_df['high'], group_df['low'], group_df['close'], append=False)

                # 安全地连接所有指标结果
                group_df = pd.concat([group_df, macd_cols, cci_cols, rsi6_cols, rsi14_cols, boll_cols, kdj_cols], axis=1)

                # --- MACD 信号检查 ---
                if len(group_df) >= 2 and 'MACD_12_26_9' in group_df.columns:
                    last_day_macd = group_df.iloc[-1]
                    prev_day_macd = group_df.iloc[-2]
                    is_golden_cross = (prev_day_macd['MACD_12_26_9'] < prev_day_macd['MACDs_12_26_9']) and (
                            last_day_macd['MACD_12_26_9'] > last_day_macd['MACDs_12_26_9'])
                    if is_golden_cross:
                        stock_info = source_df_clean[source_df_clean['股票代码'] == code].iloc[0]
                        results['macd'].append({
                            '股票代码': code,
                            '股票简称': stock_info.get('股票简称', 'N/A'),
                            'MACD (DIF)': f"{last_day_macd['MACD_12_26_9']:.2f}",
                            'MACD信号线 (DEA)': f"{last_day_macd['MACDs_12_26_9']:.2f}",
                            'MACD动能柱': f"{last_day_macd['MACDh_12_26_9']:.2f}",
                            'MACD买卖信号': '金叉 (买入信号)',
                        })

                # --- CCI 信号检查 ---
                if len(group_df) >= 2 and 'CCI_14_0.015' in group_df.columns:
                    last_day_cci = group_df.iloc[-1]
                    prev_day_cci = group_df.iloc[-2]
                    is_oversold_signal = prev_day_cci['CCI_14_0.015'] < -100 and last_day_cci['CCI_14_0.015'] > -100
                    if is_oversold_signal:
                        stock_info = source_df_clean[source_df_clean['股票代码'] == code].iloc[0]
                        results['cci'].append({
                            '股票代码': code,
                            '股票简称': stock_info.get('股票简称', 'N/A'),
                            '最新CCI值': f"{last_day_cci['CCI_14_0.015']:.2f}",
                            'CCI买卖信号': '超卖买入信号',
                        })

                # --- RSI 信号检查 ---
                if len(group_df) >= 2 and 'RSI_6' in group_df.columns and 'RSI_14' in group_df.columns:
                    last_day_rsi = group_df.iloc[-1]
                    prev_day_rsi = group_df.iloc[-2]
                    is_golden_cross_rsi = (prev_day_rsi['RSI_6'] < prev_day_rsi['RSI_14']) and (
                            last_day_rsi['RSI_6'] > last_day_rsi['RSI_14'])
                    is_rsi14_in_range = 60 <= last_day_rsi['RSI_14'] <= 80
                    if is_golden_cross_rsi and is_rsi14_in_range:
                        stock_info = source_df_clean[source_df_clean['股票代码'] == code].iloc[0]
                        results['rsi'].append({
                            '股票代码': code,
                            '股票简称': stock_info.get('股票简称', 'N/A'),
                            'RSI6': round(last_day_rsi['RSI_6'], 2),
                            'RSI14': round(last_day_rsi['RSI_14'], 2),
                            'RSI买卖信号': '金叉 (买入信号)',
                        })

                # --- 新增 BOLL 信号检查 ---
                if 'BBL_20_2.0' in group_df.columns:
                    last_day = group_df.iloc[-1]
                    # 价格差与带宽的比值（判断价格是否在下轨线附近）
                    price_diff_to_lower = last_day['close'] - last_day['BBL_20_2.0']
                    band_width = last_day['BBU_20_2.0'] - last_day['BBL_20_2.0']

                    # 检查 1：价格刚触及下轨（收盘价高于下轨线，且与下轨线的距离小于带宽的 5%）
                    is_near_lower_band = (last_day['close'] > last_day['BBL_20_2.0']) and (
                            price_diff_to_lower / band_width < 0.05) if band_width > 0 else False

                    # 检查 2：波动率处于低位（带宽小于过去 20 天带宽平均值的 80%）
                    avg_band_width = (group_df['BBU_20_2.0'] - group_df['BBL_20_2.0']).rolling(window=20).mean().iloc[-1]
                    is_low_volatility = band_width < avg_band_width * 0.8 if avg_band_width > 0 else False

                    signal = 'N/A'
                    if is_low_volatility:
                        signal = '低波动率'
                    if is_near_lower_band:
                        signal = '下轨线附近买入'
                    if is_low_volatility and is_near_lower_band:
                        signal = '低波动率 & 下轨线附近买入'

                    if signal != 'N/A':
                        stock_info = source_df_clean[source_df_clean['股票代码'] == code].iloc[0]
                        results['boll'].append({
                            '股票代码': code,
                            '股票简称': stock_info.get('股票简称', 'N/A'),
                            'BOLL波动性信号': signal,
                            'BOLL_BandWidth': round(band_width, 2),
                            'BOLL_PercentB': round((last_day['close'] - last_day['BBL_20_2.0']) / band_width, 2)
                            if band_width > 0 else 0,
                        })

                # --- 新增 KDJ 信号检查 ---
                if 'K' in group_df.columns:
                    last_day_kdj = group_df.iloc[-1]
                    prev_day_kdj = group_df.iloc[-2]
                    
                    signal = 'N/A'
                    # 1. KDJ 超卖 (K, D, J < 30) 且 K 线向上穿过 D 线 (金叉)
                    is_oversold_golden_cross = (
                        last_day_kdj['K'] > last_day_kdj['D'] and
                        prev_day_kdj['K'] < prev_day_kdj['D'] and
                        last_day_kdj['K'] < 30 and last_day_kdj['D'] < 30 and last_day_kdj['J'] < 30
                    )
                    # 2. 连续两日 KDJ 处于超卖区域 (K < 20)
                    is_two_day_oversold = (
                        prev_day_kdj['K'] < 20 and last_day_kdj['K'] < 20
                    )

                    if is_oversold_golden_cross:
                        signal = '超卖金叉 (买入信号)'
                    elif is_two_day_oversold:
                        signal = '连续超卖'

                    if signal != 'N/A':
                        stock_info = source_df_clean[source_df_clean['股票代码'] == code].iloc[0]
                        results['kdj'].append({
                            '股票代码': code,
                            '股票简称': stock_info.get('股票简称', 'N/A'),
                            'KDJ买卖信号': signal,
                            'K': round(last_day_kdj['K'], 2),
                            'D': round(last_day_kdj['D'], 2),
                            'J': round(last_day_kdj['J'], 2),
                        })

            except Exception as e:
                print(f"[ERROR] 错误：计算 {code} 的技术指标时出错: {e}，已跳过。")

        # 转换为 DataFrame
        macd_df = pd.DataFrame(results['macd'])
        cci_df = pd.DataFrame(results['cci'])
        rsi_df = pd.DataFrame(results['rsi'])
        boll_df = pd.DataFrame(results['boll'])
        kdj_df = pd.DataFrame(results['kdj'])

        print(f"技术指标分析完成：MACD金叉 {len(macd_df)} 只，CCI超卖 {len(cci_df)} 只，RSI金叉 {len(rsi_df)} 只，BOLL低波 {len(boll_df)} 只，KDJ信号 {len(kdj_df)} 只。")

        return {
            'macd_df': macd_df,
            'cci_df': cci_df,
            'rsi_df': rsi_df,
            'boll_df': boll_df,
            'kdj_df': kdj_df,
        }

    def calculate_score(self, row: pd.Series) -> int:
        """根据多因子指标计算总评分。"""
        score = 0
        factors = {
            # 技术指标 (1-3分)
            'MACD买卖信号': 3,
            'CCI买卖信号': 2,
            'RSI买卖信号': 2,
            'KDJ买卖信号': 3,
            '均线多头排列': 4,  # 加强均线多头排列权重
            'BOLL波动性信号': 2,

            # 选股策略指标 (3-5分)
            '强势股池': 5,
            '持续放量信号': 4,
            '连涨天数': 3,
            '量价齐升天数': 3,
            '流入资金': 5,  # 归属于资金流向，但直接从 DF 中获取

            # 基本面/研报指标 (2-5分)
            '机构投资评级(近六个月)-买入': 5,  # 研报数量
        }

        # 检查买卖信号
        for col in ['MACD买卖信号', 'CCI买卖信号', 'RSI买卖信号', 'KDJ买卖信号']:
            if '买入' in str(row.get(col, '')):
                score += factors.get(col, 0)

        # 检查排列/波动信号
        if str(row.get('均线多头排列', '')) == '是':
            score += factors.get('均线多头排列', 0)
        
        if '买入' in str(row.get('BOLL波动性信号', '')):
            score += factors.get('BOLL波动性信号', 0)


        # 检查强势股池
        if str(row.get('强势股池', '')) == '是':
            score += factors.get('强势股池', 0)

        # 检查持续放量信号 (通过天数判断，但这里是信号列)
        if str(row.get('持续放量信号', '')) == '已满足':
            score += factors.get('持续放量信号', 0)

        # 根据天数指标加分 (确保转换为数字)
        for col in ['连涨天数', '量价齐升天数', '持续放量天数']:
            try:
                days = int(row.get(col, 0))
                if days >= 2:
                    score += factors.get(col, 0)
            except (ValueError, TypeError):
                pass # 如果不是数字或缺失则跳过

        # 检查研报数量
        try:
            # 兼容缺失值处理，使用 float(row.get(col, 0)) 来获取值，如果找不到默认为 0
            rating = float(row.get('机构投资评级(近六个月)-买入', 0))
            if rating >= 2:
                # 给分：2-3篇 +5分，4篇及以上 +10分
                if rating >= 4:
                    score += 10
                elif rating >= 2:
                    score += 5
        except (ValueError, TypeError):
            pass

        # 检查资金流向
        if '流入资金' in row.index:
            try:
                inflow = float(row['流入资金'])
                if inflow > 0:
                    score += factors.get('流入资金', 0)
            except (ValueError, TypeError):
                pass

        return score

    def find_recommended_stocks_with_score(self, macd_df: pd.DataFrame, cci_df: pd.DataFrame, xstp_df: pd.DataFrame,
                                           rsi_df: pd.DataFrame, strong_stocks_df: pd.DataFrame,
                                           filtered_spot: pd.DataFrame, consecutive_rise_df: pd.DataFrame,
                                           boll_df: pd.DataFrame, ljqs_df: pd.DataFrame, cxfl_df: pd.DataFrame,
                                           market_fund_flow_df: pd.DataFrame, kdj_df: pd.DataFrame,
                                           industry_map: Dict[str, str]
                                           ) -> pd.DataFrame:
        """
        基于多因子评分模型筛选推荐股票。
        """

        # 0. 确定所有候选股票代码
        all_codes = set()
        for df in [macd_df, cci_df, xstp_df, rsi_df, strong_stocks_df, consecutive_rise_df, boll_df, ljqs_df, cxfl_df, kdj_df]:
            if not df.empty and '股票代码' in df.columns:
                all_codes.update(df['股票代码'].unique())

        if not all_codes:
            print("[WARN] 所有因子筛选结果均为空，无法生成推荐股票。")
            return pd.DataFrame()

        print(f"\n合并所有候选股票，共 {len(all_codes)} 只。")

        # 1. 构造基础 DataFrame
        final_df = pd.DataFrame({'股票代码': list(all_codes)})

        # 2. 合并基本信息 (股票简称)
        temp_name_df = pd.concat([
            df[['股票代码', '股票简称']]
            for df in [macd_df, cci_df, xstp_df, rsi_df, strong_stocks_df, consecutive_rise_df, boll_df, ljqs_df, cxfl_df, kdj_df]
            if not df.empty and '股票简称' in df.columns
        ]).drop_duplicates(subset=['股票代码'])

        final_df = pd.merge(final_df, temp_name_df, on='股票代码', how='left')
        
        # 3. 合并所有信号列 (使用优化后的配置和循环)
        
        # 预处理 XSTP DF以匹配新的列名
        xstp_processed = xstp_df.rename(columns={'完全多头排列': '均线多头排列'})
        
        all_signal_dfs_config = {
            macd_df: ['MACD买卖信号', 'MACD (DIF)', 'MACD信号线 (DEA)', 'MACD动能柱'],
            cci_df: ['CCI买卖信号', '最新CCI值'],
            rsi_df: ['RSI买卖信号', 'RSI6', 'RSI14'],
            boll_df: ['BOLL波动性信号', 'BOLL_BandWidth', 'BOLL_PercentB'],
            kdj_df: ['KDJ买卖信号', 'K', 'D', 'J'],
            xstp_processed: ['均线多头排列'],
            strong_stocks_df: ['强势股池'],
            consecutive_rise_df: ['连涨天数'],
            ljqs_df: ['量价齐升天数'],
            cxfl_df: ['持续放量天数'],
            market_fund_flow_df: ['流入资金'],
        }

        # 循环合并
        for df, cols in all_signal_dfs_config.items():
            if not df.empty and '股票代码' in df.columns:
                cols_to_merge = ['股票代码'] + [col for col in cols if col in df.columns]
                # 注意：确保合并的 DF 中 '股票简称' 列不会覆盖掉已有的简称，这里只取信号列
                df_to_merge = df[cols_to_merge].drop_duplicates(subset=['股票代码'])
                final_df = pd.merge(final_df, df_to_merge, on='股票代码', how='left')


        # --------------------------------------------------------------------------
        # >>> 关键修复步骤：确保所有信号列都存在并填充默认值，防止 KeyError
        # --------------------------------------------------------------------------
        signal_columns_to_ensure = [
            'MACD买卖信号', 'CCI买卖信号', 'RSI买卖信号', 'KDJ买卖信号', 
            '均线多头排列', 'BOLL波动性信号', '强势股池', 
            '连涨天数', '量价齐升天数', '持续放量天数', '持续放量信号',
            'MACD (DIF)', 'MACD信号线 (DEA)', 'MACD动能柱', '最新CCI值', 'RSI6', 'RSI14',
            'K', 'D', 'J', 'BOLL_BandWidth', 'BOLL_PercentB', '流入资金' # 详情列也要确保存在
        ]

        # 循环检查并创建/填充列
        for col in signal_columns_to_ensure:
            if col not in final_df.columns:
                # 如果列不存在，则创建并填充默认值
                if '天数' in col:
                    final_df[col] = 0
                elif col in ['强势股池', '均线多头排列']:
                    final_df[col] = '否'
                elif col == '持续放量信号':
                    final_df[col] = '未满足'
                elif '买卖信号' in col or '波动性信号' in col:
                    final_df[col] = 'N/A'
                elif col in ['流入资金', 'MACD (DIF)', 'MACD信号线 (DEA)', 'MACD动能柱', '最新CCI值', 'RSI6', 'RSI14', 'K', 'D', 'J', 'BOLL_BandWidth', 'BOLL_PercentB']:
                     final_df[col] = np.nan # 数值列用 NaN
                else:
                    final_df[col] = 'N/A' # Default fallback
            else:
                # 如果列存在，但合并结果是 NaN，则填充默认值
                if '天数' in col:
                    # 确保天数列是数字，并填充 0
                    final_df[col] = pd.to_numeric(final_df[col], errors='coerce').fillna(0).astype(int)
                elif col in ['强势股池', '均线多头排列']:
                    final_df[col].fillna('否', inplace=True)
                elif col == '持续放量信号':
                    final_df[col].fillna('未满足', inplace=True)
                elif '买卖信号' in col or '波动性信号' in col:
                    final_df[col].fillna('N/A', inplace=True)
                # 数值列统一填充为 NaN，方便后续处理
                elif col in ['流入资金', 'MACD (DIF)', 'MACD信号线 (DEA)', 'MACD动能柱', '最新CCI值', 'RSI6', 'RSI14', 'K', 'D', 'J', 'BOLL_BandWidth', 'BOLL_PercentB']:
                    # 仅填充字符串 'N/A' 导致的 NaN
                    final_df[col] = pd.to_numeric(final_df[col], errors='coerce') 

        # 重新计算 '持续放量信号'，确保与 '持续放量天数' 对应
        final_df['持续放量信号'] = final_df['持续放量天数'].apply(lambda x: '已满足' if x >= 2 else '未满足')

        # --------------------------------------------------------------------------

        # 4. 合并最新价和研报数据（用于评分）
        final_df = pd.merge(final_df, filtered_spot[['股票代码', '当前价格']], on='股票代码', how='left')
        
        # 合并主力研报数据（注意：这里需要确保主力研报数据包含 '机构投资评级(近六个月)-买入' 列）
        # process_main_report_sheet 返回的是 profit_df 的筛选结果，包含评分所需的列
        main_report_sheet = self.process_main_report_sheet(filtered_profit_df, filtered_spot)
        final_df = pd.merge(final_df, main_report_sheet[['股票代码', '机构投资评级(近六个月)-买入']], on='股票代码', how='left')
        
        # 5. 合并所属行业信息 (新功能)
        print("正在合并所属行业信息...")
        final_df['所属行业'] = final_df['股票代码'].apply(lambda code: industry_map.get(code, 'N/A'))

        # 6. 计算总评分
        final_df['总评分'] = final_df.apply(self.calculate_score, axis=1)

        # 7. 筛选逻辑
        # 统计技术指标信号列满足“买入”或“低波动”条件的股票
        signal_cols = ['MACD买卖信号', 'CCI买卖信号', 'RSI买卖信号', 'KDJ买卖信号', '均线多头排列', 'BOLL波动性信号']

        # 计算技术指标满足数量
        final_df['技术指标满足数量'] = final_df.apply(
            lambda row: sum(
                1 for col in signal_cols if '买入' in str(row[col]) or '低波动' in str(row[col]) or str(row[col]) == '是'
            ),
            axis=1
        )

        # 定义满足条件的股票：
        # 条件 1: 总评分 >= 8 分
        is_high_score = final_df['总评分'] >= 8
        # 条件 2: 至少满足 2 个技术指标
        is_tech_satisfied = final_df['技术指标满足数量'] >= 2
        # 条件 3: 必须有股票简称和当前价格
        is_valid_stock = final_df['股票简称'].notna() & final_df['当前价格'].notna()

        # 最终推荐条件 (总评分高或技术指标满足数量多且为有效股票)
        is_recommended = (is_high_score | is_tech_satisfied) & is_valid_stock

        recommended_df = final_df[is_recommended].sort_values(by='总评分', ascending=False).reset_index(drop=True)

        # 8. 添加股票链接和序号
        recommended_df['完整股票编码'] = recommended_df['股票代码'].apply(format_stock_code)
        recommended_df['股票链接'] = recommended_df['完整股票编码'].apply(
            lambda x: f'https://xueqiu.com/S/{x}' if x != 'N/A' else 'N/A'
        )
        recommended_df['序号'] = recommended_df.index + 1

        # 9. 确定最终列顺序 (处理填充后的 NaN)
        
        # 非数值列，填充 'N/A'
        string_cols = ['股票简称', '所属行业', 'MACD买卖信号', 'CCI买卖信号', 'RSI买卖信号', 'KDJ买卖信号', 
                       '均线多头排列', 'BOLL波动性信号', '强势股池', '持续放量信号', '股票链接']
        for col in string_cols:
            if col in recommended_df.columns:
                 recommended_df[col].fillna('N/A', inplace=True)

        # 数值列，填充 0 或 N/A（对于详情列）
        recommended_df.fillna({'当前价格': 0, '总评分': 0, '技术指标满足数量': 0, 
                               '连涨天数': 0, '量价齐升天数': 0, '持续放量天数': 0,
                               '机构投资评级(近六个月)-买入': 0, '流入资金': 0, 
                               'MACD (DIF)': 'N/A', 'MACD信号线 (DEA)': 'N/A', 'MACD动能柱': 'N/A', 
                               '最新CCI值': 'N/A', 'RSI6': 'N/A', 'RSI14': 'N/A',
                               'K': 'N/A', 'D': 'N/A', 'J': 'N/A', 
                               'BOLL_BandWidth': 'N/A', 'BOLL_PercentB': 'N/A',
                               }, inplace=True)


        final_cols_order = [
            '序号', '股票代码', '股票简称', '所属行业', '当前价格', '总评分', '技术指标满足数量',
            # 技术指标
            'MACD买卖信号', 'CCI买卖信号', 'RSI买卖信号', 'KDJ买卖信号', '均线多头排列', 'BOLL波动性信号',
            # 其他信号
            '强势股池', '持续放量信号', '连涨天数', '量价齐升天数', '持续放量天数',
            # 研报/资金
            '机构投资评级(近六个月)-买入', '流入资金',
            # 详情列
            'MACD (DIF)', 'MACD信号线 (DEA)', 'MACD动能柱', '最新CCI值', 'RSI6', 'RSI14',
            'K', 'D', 'J', 'BOLL_BandWidth', 'BOLL_PercentB',
            # 链接
            '股票链接'
        ]

        # 筛选出实际存在的列，并按照顺序排列
        existing_final_cols = [col for col in final_cols_order if col in recommended_df.columns]

        print(f"多因子评分筛选完成，推荐股票数量: {len(recommended_df)} 只。")
        return recommended_df[existing_final_cols]


# ==============================================================================
# Excel报告生成类
# ==============================================================================
class ReportGenerator:
    """
    负责将数据写入结构化的 Excel 报告。
    """

    def __init__(self, config: Config):
        self.config = config
        os.makedirs(self.config.SAVE_DIRECTORY, exist_ok=True)
        self.file_name = f"主力研报筛选_{datetime.now().strftime('%Y%m%d%H%M%S')}.xlsx"
        self.file_path = os.path.join(self.config.SAVE_DIRECTORY, self.file_name)
        self.workbook = None
        self.writer = None

    def initialize_workbook(self):
        """初始化 Excel 写入器和工作簿。"""
        # 使用 xlsxwriter 引擎来支持格式化
        self.writer = pd.ExcelWriter(self.file_path, engine='xlsxwriter')
        self.workbook = self.writer.book

    def write_sheet(self, sheet_name: str, df: pd.DataFrame):
        """将 DataFrame 写入指定的 Excel 工作表。"""
        if df is None or df.empty:
            print(f"  - 警告: 工作表 '{sheet_name}' 数据为空，将跳过。")
            return

        df.to_excel(self.writer, sheet_name=sheet_name, index=False)
        worksheet = self.writer.sheets[sheet_name]

        # 设置列宽
        for i, col in enumerate(df.columns):
            max_len = max(df[col].astype(str).str.len().max(), len(col)) + 2
            max_len = min(max_len, 40)  # 限制最大宽度
            worksheet.set_column(i, i, max_len)

        # 添加表格格式（仅对“指标汇总”和“主力研报筛选”应用）
        if sheet_name in ['指标汇总', '主力研报筛选']:
            num_rows, num_cols = df.shape
            if num_rows > 0:
                worksheet.add_table(0, 0, num_rows, num_cols - 1, {
                    'columns': [{'header': col} for col in df.columns],
                    'style': 'Table Style Light 1'
                })

        # 针对“指标汇总”工作表，添加超链接格式
        if sheet_name == '指标汇总':
            link_col_index = df.columns.get_loc('股票链接')
            # 链接列隐藏，使用 HYPERLINK() 公式
            worksheet.set_column(link_col_index, link_col_index, None, None, {'hidden': True})

            for row_num, link in enumerate(df['股票链接']):
                if link != 'N/A':
                    code = df.iloc[row_num]['股票代码']
                    # 写入链接，将链接文本显示为股票代码
                    worksheet.write_url(row_num + 1, df.columns.get_loc('股票简称'), link, string=code)
                    
            # 突出显示总评分
            score_format = self.workbook.add_format({'bg_color': '#D9EAD3'}) # 浅绿色背景
            score_col_index = df.columns.loc['总评分']
            worksheet.set_column(score_col_index, score_col_index, 10, score_format) # 设置列宽和格式

        print(f"  - 成功写入工作表: {sheet_name}")

    def generate_report(self, sheets_data: Dict[str, pd.DataFrame]):
        """生成最终的 Excel 报告。"""
        self.initialize_workbook()
        try:
            for sheet_name, df in sheets_data.items():
                self.write_sheet(sheet_name, df)
            self.writer.close()
            print(f"\n[SUCCESS] Excel 报告已保存至: {self.file_path}")
        except Exception as e:
            print(f"[ERROR] 错误：生成 Excel 报告时出错: {e}")
        finally:
            self.cleanup()

    def cleanup(self):
        """清理临时数据文件。"""
        print("\n正在清理临时数据文件...")
        try:
            for file_name in os.listdir(self.config.TEMP_DATA_DIRECTORY):
                file_path = os.path.join(self.config.TEMP_DATA_DIRECTORY, file_name)
                # 只删除今日生成的缓存文件
                if file_name.endswith(f"{self.fetcher.today_str}.txt") or file_name.endswith(f"_经清洗_{self.fetcher.today_str}.txt"):
                    os.remove(file_path)
        except Exception as e:
            print(f"[WARN] 警告：清理临时文件失败: {e}")


# ==============================================================================
# 数据流控制类
# ==============================================================================
class StockDataPipeline:
    """
    负责协调数据获取、处理和报告生成的整个流程。
    """

    def __init__(self):
        self.config = Config()
        self.fetcher = DataFetcher(self.config)
        self.processor = DataProcessor(self.fetcher)
        self.reporter = ReportGenerator(self.config)

    def run(self):
        """执行整个数据分析流程。"""
        start_time = time.time()
        print(">>> 启动股票数据多因子筛选流程...")

        try:
            # 1. 数据获取
            # 获取主力研报盈利预测 (作为基础数据集)
            profit_df_raw = self.fetcher.fetch_with_cache(ak.stock_profit_forecast_ths, '主力研报盈利预测')
            filtered_profit_df = self.processor.process_profit_data(profit_df_raw)
            all_ta_codes = filtered_profit_df['股票代码'].tolist()

            # 获取 A股实时行情 (获取最新价)
            filtered_spot_raw = self.fetcher.fetch_with_cache(ak.stock_zh_a_spot_em, 'A股实时行情')
            filtered_spot = self.processor.process_spot_data(filtered_spot_raw, filtered_profit_df)

            # 获取市场资金流向 (用于评分)
            market_fund_flow_df_raw = self.fetcher.fetch_with_cache(ak.stock_fund_flow_individual_rank_em, '市场资金流向', symbol='5日')
            processed_market_fund_flow = self.processor.process_market_fund_flow(market_fund_flow_df_raw)

            # 获取板块成分股 (用于获取热门行业股票)
            top_industry_cons_df = self.fetcher.get_top_industry_stocks()

            # 获取均线多头排列/向上突破数据
            df_xstp20 = self.fetcher.fetch_with_cache(ak.stock_rank_xstp_ths, '向上突破20日均线', symbol="20日")
            df_xstp60 = self.fetcher.fetch_with_cache(ak.stock_rank_xstp_ths, '向上突破60日均线', symbol="60日")
            df_xstp90 = self.fetcher.fetch_with_cache(ak.stock_rank_xstp_ths, '向上突破90日均线', symbol="90日")
            processed_xstp_df = self.processor.process_and_merge_xstp_data(df_xstp20, df_xstp60, df_xstp90, filtered_spot)
            
            # 获取强势股池数据
            strong_stocks_df_raw = self.fetcher.fetch_with_cache(ak.stock_rank_cxg_ths, '强势股池')
            processed_strong_stocks = self.processor.process_general_rank(strong_stocks_df_raw, '强势股池')
            
            # 获取连续上涨数据
            consecutive_rise_df_raw = self.fetcher.fetch_with_cache(ak.stock_rank_ljqd_ths, '连续上涨', symbol='5日')
            processed_consecutive_rise = self.processor.process_general_rank(consecutive_rise_df_raw, '连续上涨')

            # 获取量价齐升数据
            ljqs_df_raw = self.fetcher.fetch_with_cache(ak.stock_rank_ljqs_ths, '量价齐升')
            processed_ljqs = self.processor.process_general_rank(ljqs_df_raw, '量价齐升')

            # 获取持续放量数据
            cxfl_df_raw = self.fetcher.fetch_continuous_volume_increase()
            processed_cxfl = self.processor.process_continuous_volume_increase(cxfl_df_raw)

            # 确定所有需要进行技术分析的股票代码（研报股 + 均线股 + 强势股 + ...）
            all_ta_codes.extend(processed_xstp_df['股票代码'].tolist())
            all_ta_codes.extend(processed_strong_stocks['股票代码'].tolist())
            all_ta_codes.extend(processed_consecutive_rise['股票代码'].tolist())
            all_ta_codes.extend(processed_ljqs['股票代码'].tolist())
            all_ta_codes.extend(processed_cxfl['股票代码'].tolist())
            all_ta_codes = list(set(all_ta_codes)) # 去重

            # 获取所有需要分析股票的历史数据
            hist_df_all = self.fetcher.fetch_hist_data_parallel(all_ta_codes, days=180)

            # 2. 数据处理与技术分析
            # 集中计算 MACD, CCI, RSI, BOLL, KDJ
            ta_results = self.processor.process_all_technical_indicators(
                all_ta_codes, hist_df_all, filtered_spot
            )
            macd_df = ta_results['macd_df']
            cci_df = ta_results['cci_df']
            rsi_df = ta_results['rsi_df']
            boll_df = ta_results['boll_df']
            kdj_df = ta_results['kdj_df']

            # 获取所有候选股票的行业信息 (包括所有技术指标的股票，以确保最终推荐列表中行业信息的完整性)
            industry_map = self.fetcher.get_industry_map_parallel(all_ta_codes)

            # 3. 多因子评分与筛选
            # 这一步是关键，修复了 KeyError 的问题
            recommended_stocks = self.processor.find_recommended_stocks_with_score(
                macd_df, cci_df, processed_xstp_df, rsi_df, processed_strong_stocks,
                filtered_spot, processed_consecutive_rise, boll_df, processed_ljqs,
                processed_cxfl, processed_market_fund_flow, kdj_df, industry_map,
                filtered_profit_df # 传入研报数据以确保评分列存在
            )

            # 4. 生成报告
            main_report_sheet = self.processor.process_main_report_sheet(filtered_profit_df, filtered_spot)
            
            sheets_data = {
                '指标汇总': recommended_stocks,  # 放在第一个工作表
                '主力研报筛选': main_report_sheet,
                '实时行情': filtered_spot,
                '市场资金流向': processed_market_fund_flow,
                '前十板块成分股': top_industry_cons_df,  
                '均线多头排列': processed_xstp_df, # 只保留一份，不再有 '向上突破' 重复
                '强势股池': processed_strong_stocks,
                '连续上涨': processed_consecutive_rise,
                '量价齐升': processed_ljqs,
                '持续放量': processed_cxfl,
                'MACD金叉': macd_df,
                'CCI超卖': cci_df,
                'RSI金叉': rsi_df,
                'BOLL低波': boll_df,
                'KDJ超卖金叉': kdj_df,  
            }
            self.reporter.generate_report(sheets_data)
        except Exception as e:
            print(f"[FATAL] 致命错误：数据分析流程意外终止。原因: {e}")
            # 如果是致命错误，尝试清理，但不要掩盖错误
            try:
                 self.reporter.cleanup()
            except:
                 pass
            raise # 重新抛出异常，以便用户看到错误
        finally:
            end_time = time.time()
            print(f"\n>>> 流程结束。总耗时: {end_time - start_time:.2f} 秒。")


if __name__ == '__main__':
    pipeline = StockDataPipeline()
    pipeline.run()
